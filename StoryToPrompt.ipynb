{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMklOQrgDuZh6XQ1GJYeXvO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hari-priya-Sridharan/PagesToPixels/blob/develop/StoryToPrompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cErt75cDtmz",
        "outputId": "04680ac1-b538-4603-cd0a-1a0607aad642"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/227.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GI3BZWGgCkY7"
      },
      "outputs": [],
      "source": [
        "import configparser\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Read API key from credential.ini\n",
        "config = configparser.ConfigParser()\n",
        "config.read('credential.ini')\n",
        "API_KEY = config['openai']['APIKEY']\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "# Function to split text into paragraphs\n",
        "\n",
        "base_prompt = \"\"\"// create a prompt that dalle can use to\n",
        "generate the image and abide to the following policy when a story is given:\n",
        "// 1. The prompt must be in English. Translate to English if needed\n",
        "// 2. DO NOT ask for permission to generate the image, just do it!\n",
        "// 3. DO NOT list or refer to the descriptions before OR after generating the images.\n",
        "// 4. Split the story in relevant parts and create prompt for each parts.\n",
        "// 5. The generated prompt sent to dalle should be very detailed with key points\n",
        "long and should have prompt only. Avoid adding additional instructions or information and references to previous prompts\n",
        "// 6. Each prompt should be less than 100 words with line inbetween each prompt and should follow the below\n",
        "\n",
        "To ensure consistency and desired output, a specific formula that will be used for creating prompts for Dall-E. This formula comprises the following elements, forming a cohesive sentence:\n",
        "1. [Subject Description]:  ALL character descriptions in the Base Image Prompts below for each character must be FULLY included in EVERY image prompt.\n",
        "2. [Environment Description]: Detailing the scene's setting based on story or generating an appropriate background if not specified.\n",
        "3. [Art Style]: Consistently employing high-resolution, disney 3D animated film style with detailed rendering, closely matching the style in the story.\n",
        "4. [Color and Light]: Describing main colors and lighting, focusing on bright, soft lights and a warm feel.\n",
        "5. [Camera Angle and Composition]: Indicating the perspective for the scene,subject focused, personality view, to enhance the storytelling aspect.\n",
        "6. [Avoid]: ugliness, deformities, noise, blurriness, distortion, lack of focus, poor anatomy, additional limbs, inadequately drawn faces, hands, or fingers.\n",
        "\n",
        "\n",
        "namespace dalle {\n",
        "// Create images from a text-only prompt.\n",
        "\n",
        "type text2im =(:{\n",
        "// The size of the requested image. Use 1024×1024 square) as the default\n",
        "// The number of images to generate.  generate 1\n",
        "image.\n",
        "n?: number,\n",
        "// The detailed image description, potentially modified to abide by the dalle policies.\n",
        "\n",
        "prompt: string,\n",
        "// If the user references a previous image, this field should be populated with the\n",
        "gen_id from the dalle image metadata.\n",
        "\n",
        "referenced_image_ids?:string[],}//namspace dalle\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_dalle_prompt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            # model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": base_prompt + \"Story : \" + prompt}\n",
        "            ],\n",
        "            temperature=1.2,\n",
        "            max_tokens=3000,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# Read text from file\n",
        "def read_file(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "\n",
        "# Write text to file\n",
        "def write_file(filename, content):\n",
        "    with open(filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(content)\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main(input_filename, output_filename):\n",
        "    output_text = \"\"\n",
        "    output_text += generate_dalle_prompt(\n",
        "            read_file(input_filename))  # Add double newline between paragraphs\n",
        "\n",
        "    write_file(output_filename, output_text)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_filename = \"story.txt\"  # Replace with your input file name\n",
        "    output_filename = \"prompts.txt\"  # Replace with your desired output file name\n",
        "    main(input_filename, output_filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt generation for Playground AI model"
      ],
      "metadata": {
        "id": "5sBHUac9F0nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import configparser\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Read API key from credential.ini\n",
        "config = configparser.ConfigParser()\n",
        "config.read('credential.ini')\n",
        "API_KEY = config['openai']['APIKEY']\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "# Function to split text into paragraphs\n",
        "\n",
        "base_prompt = \"\"\"// create a prompt that dalle can use to\n",
        "generate the image and abide to the following policy when a story is given:\n",
        "// 1. The prompt must be in English. Translate to English if needed\n",
        "// 2. DO NOT ask for permission to generate the image, just do it!\n",
        "// 3. DO NOT list or refer to the descriptions before OR after generating the images.\n",
        "// 4. Split the story into as many relevant parts as possible and create prompt for each parts.\n",
        "// 5. The generated prompt sent to dalle should be with key points\n",
        "long and should have prompt only. Avoid adding additional instructions or information and references to previous prompts\n",
        "// 6. Each prompt should be less than \"30 words\" only with line inbetween each prompt and should follow the below\n",
        "\n",
        "To ensure consistency and desired output, a specific formula that will be used for creating prompts for Dall-E. This formula comprises the following elements, forming a cohesive sentence:\n",
        "1. [Subject Description]:  ALL character descriptions and appearances in the Base Image Prompts below for each character must be FULLY included in EVERY image prompt.\n",
        "2. [Environment Description]: Detailing the scene's setting based on story or generating an appropriate background if not specified.\n",
        "3. [Art Style]: high-resolution, disney 3D animated film style, detailed rendering.\n",
        "4. [Color and Light]: Describing main colors and lighting, focusing on bright, soft lights and a warm feel.\n",
        "5. [Camera Angle and Composition]: Indicating the perspective for the scene,subject focused, personality view, to enhance the storytelling aspect.\n",
        "6. [Avoid]: ugliness, deformities, noise, blurriness, distortion, lack of focus, poor anatomy.\n",
        "\n",
        "// The detailed image description, potentially modified to abide by the dalle policies.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_dalle_prompt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            # model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": base_prompt + \"Story : \" + prompt}\n",
        "            ],\n",
        "            temperature=1.2,\n",
        "            max_tokens=3000,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# Read text from file\n",
        "def read_file(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "\n",
        "# Write text to file\n",
        "def write_file(filename, content):\n",
        "    with open(filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(content)\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main(input_filename, output_filename):\n",
        "    output_text = \"\"\n",
        "    output_text += generate_dalle_prompt(\n",
        "            read_file(input_filename))  # Add double newline between paragraphs\n",
        "\n",
        "    write_file(output_filename, output_text)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_filename = \"story.txt\"  # Replace with your input file name\n",
        "    output_filename = \"prompts.txt\"  # Replace with your desired output file name\n",
        "    main(input_filename, output_filename)\n"
      ],
      "metadata": {
        "id": "Hu6CyfxRFecX"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}